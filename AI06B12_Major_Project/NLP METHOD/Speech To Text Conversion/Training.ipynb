{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import random\n",
    "from tensorflow.keras.layers import Dense,GRU,LSTM,Masking,Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading data stored in .pkl and .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl(path):\n",
    "    \"\"\"\n",
    "    Loads data from given path to .pkl file.\n",
    "    \"\"\"\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "audio_sequence_padded=load_pkl('processed_numpy/audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_sequence_padded=np.load('processed_numpy/txtx.npy')\n",
    "txt_sequence_length=np.load('processed_numpy/txt_length.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_chars=load_pkl('processed_numpy/unique_chars')\n",
    "ind2char=load_pkl('processed_numpy/ind2char')\n",
    "char2ind=load_pkl('processed_numpy/char2ind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "#input_shape=(2,1628,494)\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,enc_units,batch_sz):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.batch_sz=batch_sz\n",
    "        self.enc_units=enc_units\n",
    "        self.gru=GRU(self.enc_units,dropout=0.3,recurrent_dropout=0.3,return_sequences=True,return_state=True)#can add dropout and recurrent dropout if needed for regularization\n",
    "\n",
    "    def call(self,x,hidden):\n",
    "        mask =Masking(mask_value=0.0)(x) \n",
    "        output,hidden=self.gru(mask,initial_state=hidden)        #TRY WITH LSTM only cell_state will be added\n",
    "        return output,hidden                                     #(2,1628,256(enc_units)) and (2,256(enc_units))\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz,self.enc_units))\n",
    "\n",
    "encoder=Encoder(256,2)\n",
    "#sample_input\n",
    "# sample_hidden=encoder.initialize_hidden_state()\n",
    "# sample_output,sample_hidden=encoder(s,sample_hidden)\n",
    "# print(sample_output.shape)                                \n",
    "# print(sample_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units):\n",
    "        super(BahdanauAttention,self).__init__()\n",
    "        self.w1=Dense(units)\n",
    "        self.w2=Dense(units)\n",
    "        self.v=Dense(1)\n",
    "\n",
    "    def call(self,query,values):       #query:hidden_decoder size(2,256)   values:encoder_output(2,1628,256)\n",
    "        #query_shape=(bs,features)\n",
    "        #query_with_time_axis=(bs,1,features)\n",
    "        query_with_time_axis = tf.expand_dims(query,1)    #(2,1,256)      \n",
    "        #values_shape=(bs,max_len,features)\n",
    "        #self.w1(query_with_time_axis) :shape(2,1,32) for w2 (2,1628,32)\n",
    "        #tf.nn.tanh(self.w1(query_with_time_axis)+self.w2(values)):shape(2,1628,32)\n",
    "        score=self.v(tf.nn.tanh(self.w1(query_with_time_axis)+self.w2(values)))   #(2,1628,1)\n",
    "        #attention_weights shape=(bs,max_len,1)\n",
    "        attention_weights=tf.nn.softmax(score,axis=1)                              #(2,1628,1)\n",
    "\n",
    "        context_vector=attention_weights*values                                   #(2,1628,256)\n",
    "        context_vector=tf.reduce_sum(context_vector,axis=1)                       #(2,256)\n",
    "        #context_vector shape=(batch_size,hidden_size)\n",
    "\n",
    "        return context_vector,attention_weights\n",
    "\n",
    "attention_layer=BahdanauAttention(256)\n",
    "# attention_result,attention_weights=attention_layer(sample_hidden,sample_output)\n",
    "# print(attention_result.shape)\n",
    "# print(attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_unique_chars=30\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,dec_units,batch_sz):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.batch_sz=batch_sz\n",
    "        self.dec_units=dec_units\n",
    "        #Forward through unidirectional GRU\n",
    "        self.embedding=tf.keras.layers.Embedding(len_unique_chars,dec_units)\n",
    "        self.gru=GRU(dec_units,return_sequences=True,return_state=True)\n",
    "        self.fc=Dense(len_unique_chars)\n",
    "\n",
    "        #used for attention\n",
    "        self.attention=BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self,x,hidden,enc_output):\n",
    "        context_vector,attention_weights=self.attention(hidden,enc_output)\n",
    "        #(2,256) and (2,1628,1)\n",
    "        #enc_output shape=(batch_size,max_length,hidden_size)\n",
    "        x=self.embedding(x)\n",
    "        #x shape after concatenation == (batch_size,1,features+hidden_size)\n",
    "        x=tf.concat([tf.expand_dims(context_vector,1),x],axis=-1)   #(2,1,256) and(2,1,256) so x=(2,1,518)\n",
    "        #passing concatenated vector to GRU\n",
    "        output,state=self.gru(x)                                     #(2,1,256)\n",
    "        #output_shape=(batch_size*1,hidden_size)\n",
    "        output=tf.reshape(output,(-1,output.shape[2]))               #(2,256)\n",
    "        #output_shape=(batch_size,unique_chars)\n",
    "        x=self.fc(output)                                             #(2,27)\n",
    "        return x,state,attention_weights\n",
    "\n",
    "decoder=Decoder(256,2)\n",
    "# prediction,dec_hidden,_=decoder(tf.random.uniform((2,1)),sample_hidden,sample_output)\n",
    "# print(sample_decoder_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining loss func and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip = 50.0\n",
    "teacher_forcing_ratio=0.3\n",
    "learning_rate = 0.0001\n",
    "# decoder_learning_ratio = 5.0\n",
    "optimizer=tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "#REMEMBER IN SparseCategoricalCrossentropy target is in int nd prediction is in float\n",
    "loss_object=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction='none') \n",
    "#The from_logits=True attribute inform the loss function that the output values generated by the model are not normalized, a.k.a. logits. In other words, the softmax function has not been applied on them to produce a probability distribution. Therefore, the output layer in this case does not have a softmax activation function:\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir='/training_checkpoints'\n",
    "checkpoint_prefix=os.path.join(checkpoint_dir+\"ckpt\")\n",
    "checkpoint=tf.train.Checkpoint(optimizer=optimizer,\n",
    "                              encoder=encoder,\n",
    "                              decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "y=txt_sequence_padded\n",
    "X=audio_sequence_padded\n",
    "number_of_batches = (len(X)+batch_size-1)//batch_size\n",
    "sample_index = np.arange(len(X))\n",
    "val_batches=int(np.floor(number_of_batches*0.2))\n",
    "train_batches=number_of_batches-val_batches\n",
    "\n",
    "def batch_generator(batch):\n",
    "    \n",
    "    x_batch,y_batch=[],[]\n",
    "    if batch == (number_of_batches-1):\n",
    "        batch_index=sample_index[batch_size*batch::]\n",
    "    else:\n",
    "        batch_index=sample_index[batch_size*batch:batch_size*(batch+1)]\n",
    "        \n",
    "    for i in (batch_index):\n",
    "#         print(i)\n",
    "        x_batch.append(X[i].toarray())\n",
    "        y_batch.append(y[i])\n",
    "    \n",
    "    y_batch=np.array(y_batch)\n",
    "    y_batch=y_batch.astype('int32')\n",
    "    \n",
    "    x_batch=np.array(x_batch)\n",
    "    x_batch=x_batch.astype('float32')\n",
    "    \n",
    "    return x_batch,y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1,Y1=batch_generator(1349)\n",
    "# print(X1.dtype)\n",
    "# print(Y1.dtype)\n",
    "# Y1.shape\n",
    "# X1.shape\n",
    "# dummy_loss=train(X1,Y1,encoder,decoder,char2ind,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "\n",
    "# x_batch dtype=float64   and y_batch dtype is int32   number_of_batches:1352   total:2703\n",
    "def train(x_batch,y_batch,encoder,decoder,char2ind,optimizer):\n",
    "    loss=0\n",
    "    print_losses=[]\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        #Forward pass through encoder\n",
    "        enc_hidden=encoder.initialize_hidden_state()\n",
    "        encoder_outputs,encoder_hidden=encoder(x_batch,enc_hidden)\n",
    "\n",
    "        #create initial decoder input(starting with SOS_token for each sent)\n",
    "        decoder_input=tf.expand_dims([char2ind['<SOS>']]*batch_size,1)\n",
    "\n",
    "        #set initial decoder hidden state to encoders final hidden state\n",
    "        decoder_hidden=encoder_hidden\n",
    "\n",
    "        #Determine if we are using teacher forcing for iterations\n",
    "        use_teacher_forcing=True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "        #Forward batch of seq one time step at time through decoder\n",
    "        if use_teacher_forcing:\n",
    "            for t in range(1,(y_batch.shape[1])-1):\n",
    "\n",
    "                decoder_output,decoder_hidden,_=decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "               # Teacher forcing: next input is current target\n",
    "                decoder_input=np.array((y_batch[0][t],y_batch[1][t])).reshape(2,1)\n",
    "\n",
    "                real=np.array((y_batch[0][t+1],y_batch[1][t+1])).reshape(2,1)\n",
    "                loss+=loss_function(real,decoder_output)\n",
    "                \n",
    "        else:\n",
    "            for t in range(1,(y_batch.shape[1])-1):\n",
    "                decoder_output,decoder_hidden,_=decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "                topi = np.argmax(decoder_output,1).reshape(2,1)\n",
    "                decoder_input = topi\n",
    "                real=np.array((y_batch[0][t],y_batch[1][t])).reshape(2,1)\n",
    "                loss+=loss_function(real,decoder_output)\n",
    "#                 print('loss added')\n",
    "    \n",
    "    batch_loss=loss/int(y_batch.shape[1]-1)\n",
    "    \n",
    "    # Perform backpropatation\n",
    "    variables=encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients=tape.gradient(loss,variables)\n",
    "    optimizer.apply_gradients(zip(gradients,variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iters(train_batches,val_batches,encoder,decoder,char2ind,ind2char,optimizer):\n",
    "    print_loss=0\n",
    "    plot_loss=0\n",
    "    print_every=50\n",
    "    plot_every=100\n",
    "    plot_loss_list=[]\n",
    "    #TRY ADDING EPOCHS\n",
    "    start=time.time()\n",
    "    for train_batch in range(train_batches):\n",
    "        x_train,y_train=batch_generator(val_batches+train_batch)\n",
    "        train_loss=train(x_train,y_train,encoder,decoder,char2ind,optimizer)\n",
    "        print_loss+=train_loss\n",
    "        plot_loss+=train_loss\n",
    "        \n",
    "        if train_batch % print_every == 0:\n",
    "            print_loss_avg = print_loss / (print_every+1)\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f};time:{}\".format(train_batch, train_batch / train_batches * 100, print_loss_avg,time.time()-start))\n",
    "            print('_'*30)\n",
    "            print_loss = 0\n",
    "            \n",
    "        if train_batch % plot_every == 0:\n",
    "            plot_loss_list.append(plot_loss/(plot_every+1))\n",
    "            plot_loss = 0\n",
    "        \n",
    "        if train_batch > train_batches-3:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "            \n",
    "        \n",
    "        for val_batch in range(val_batches):\n",
    "            output1=[]\n",
    "            output2=[]\n",
    "            val_batch=random.randrange(0,val_batches)\n",
    "            x_val,y_val=batch_generator(val_batch)\n",
    "            input1=[ind2char[each] for each in y_val[0] if each!=0]\n",
    "            input2=[ind2char[each] for each in y_val[1] if each!=0]\n",
    "            \n",
    "            enc_hidden=encoder.initialize_hidden_state()\n",
    "            encoder_outputs,encoder_hidden=encoder(x_val,enc_hidden)\n",
    "            \n",
    "            decoder_input=tf.expand_dims([char2ind['<SOS>']]*batch_size,1)\n",
    "            decoder_hidden=encoder_hidden\n",
    "            \n",
    "            for t in range(y_val.shape[1]):\n",
    "                decoder_output,decoder_hidden,_=decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "                topi = np.argmax(decoder_output,1).reshape(2,1)\n",
    "                \n",
    "#                 print(type(topi))\n",
    "                if topi[0][0]==2 and topi[1][0]==2:   #since <EOS> occured\n",
    "                    break\n",
    "                \n",
    "                decoder_input = topi\n",
    "                \n",
    "#                 if topi[0][0]!=0:\n",
    "                output1.append(ind2char[topi[0][0]])\n",
    "#                 if topi[1][0]!=0:\n",
    "                output2.append(ind2char[topi[1][0]])\n",
    "                \n",
    "#                 real=np.array((y_batch[0][t+1],y_batch[1][t+1])).reshape(2,1)\n",
    "#                 loss+=loss_function(real,decoder_output)\n",
    "            \n",
    "#\n",
    "            \n",
    "            print('input1:{}'.format(''.join(input1)))\n",
    "            print('input2:{}'.format(''.join(input2)))\n",
    "            print('output1:{}'.format(''.join(output1)))\n",
    "            print('output2:{}'.format(''.join(output2)))\n",
    "            print('time:{}'.format(time.time()-start))\n",
    "        \n",
    "    plt.plot(plot_loss_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iters(train_batches,val_batches,encoder,decoder,char2ind,ind2char,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_example(number):\n",
    "#     Xval_exp=X[number].toarray()\n",
    "#     Xval_exp=np.array(Xval_exp)\n",
    "#     Xval_exp=Xval_exp.astype('float32')\n",
    "    \n",
    "#     Yval_exp=y[number]\n",
    "#     Yval_exp=np.array(Yval_exp)\n",
    "#     Yval_exp=Yval_exp.astype('int32')\n",
    "    \n",
    "#     return Xval_exp,Yval_exp\n",
    "\n",
    "# Xval_exppp,Yval_exppp = eval_example(3)   \n",
    "# Yval_exppp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For brevity, this error message is generated when there is not enough memory to handle the batch size.\n",
    "# ERROR:InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Cast: Dst tensor is not initialized. [Op:Cast]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading .flac file of audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "samples,sample_rate=librosa.load('LibriSpeech/dev-clean/2078/142845/2078-142845-0000.flac',sr=16000)\n",
    "\n",
    "ipd.Audio(samples, rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
